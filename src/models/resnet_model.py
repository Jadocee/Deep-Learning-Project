# File: resnet.py
#
# Author: Thomas Bandy
#
# This file contains the implementation of the ResNet18 model and the Residual Block module in PyTorch.
# The ResNet18 model is a 5-layer variant with 18 convolutional layers.
#
# References:
# - Kaiming He, et al. "Deep Residual Learning for Image Recognition." arXiv:1512.03385
# - https://blog.paperspace.com/writing-resnet-from-scratch-in-pytorch/
# - https://towardsdev.com/implement-resnet-with-pytorch-a9fb40a77448
#
# All docstrings were generated by ChatGPT.
#
# The ResNet18 model is based on the ResNet architecture proposed in the above paper,
# with modifications for the ResNet18 variant.
#
# The Residual Block module is a building block used in the ResNet18 model,
# consisting of convolutional layers, batch normalization, and skip connections.
#
# Date: May 12, 2023

import torch
from torch import nn


class ResNet18(nn.Module):
    """A PyTorch implementation of the ResNet-18 architecture.

    This class implements the ResNet-18 architecture, a widely used deep convolutional neural network architecture
    for image classification tasks. It inherits from the PyTorch nn.Module class.

    Attributes:
        - layer0 (nn.Sequential): The initial layer of the ResNet-18, consisting of a convolution, max pooling, batch
        normalization, and ReLU activation.
        - layer1 (nn.Sequential): The second layer of the ResNet-18, consisting of 2 residual blocks.
        - layer2 (nn.Sequential): The third layer of the ResNet-18, consisting of 2 residual blocks.
        - layer3 (nn.Sequential): The fourth layer of the ResNet-18, consisting of 2 residual blocks.
        - layer4 (nn.Sequential): The fifth layer of the ResNet-18, consisting of 2 residual blocks.
        - gap (torch.nn.AdaptiveAvgPool2d): Global average pooling layer.
        - fc (torch.nn.Linear): Fully connected layer for the network output.
    """

    def __init__(self, in_channels, out_channel, resblock, outputs=1000):
        """Constructs all the necessary attributes for the ResNet18 object.

        Args:
            in_channels (int): Number of input channels.

            out_channel (int): Number of output channels for the initial convolutional layer.

            resblock (nn.Module): The type of Residual Block to use. Must be a subclass of nn.Module.

            outputs (int, optional): Number of output units for the last linear layer. Defaults to 1000.
        """

        super().__init__()
        self.layer0 = nn.Sequential(
            nn.Conv2d(in_channels, out_channel, kernel_size=7, stride=2, padding=3),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(out_channel),
            nn.ReLU(),
        )

        self.layer1 = nn.Sequential(
            resblock(out_channel, out_channel, downsample=False),
            resblock(out_channel, out_channel, downsample=False),
        )

        self.layer2 = nn.Sequential(
            resblock(out_channel, (out_channel * 2), downsample=True),
            resblock((out_channel * 2), (out_channel * 2), downsample=False),
        )

        self.layer3 = nn.Sequential(
            resblock((out_channel * 2), (out_channel * 4), downsample=True),
            resblock((out_channel * 4), (out_channel * 4), downsample=False),
        )

        self.layer4 = nn.Sequential(
            resblock((out_channel * 4), (out_channel * 8), downsample=True),
            resblock((out_channel * 8), (out_channel * 8), downsample=False),
        )

        self.gap = torch.nn.AdaptiveAvgPool2d(1)
        self.fc = torch.nn.Linear((out_channel * 8), outputs)

    def forward(self, _input):
        """Performs the forward pass of the ResNet18 model.

        Args:
            _input (torch.Tensor): Input tensor.

        Returns:
            torch.Tensor: Output tensor after applying the forward pass.
        """
        _input = self.layer0(_input)
        _input = self.layer1(_input)
        _input = self.layer2(_input)
        _input = self.layer3(_input)
        _input = self.layer4(_input)
        _input = self.gap(_input)
        _input = _input.view(_input.size(0), -1)
        _input = self.fc(_input)
        return _input


class Resblock(nn.Module):
    """A residual block module for a convolutional neural network.

    Args:
        in_channels (int): Number of input channels.
        out_channels (int): Number of output channels.
        downsample (bool): Indicates if the input spatial dimensions need to be downsampled.

    Attributes:
        conv1 (nn.Conv2d): First convolutional layer.
        shortcut (nn.Sequential): Shortcut connection used for downsampling.
        conv2 (nn.Conv2d): Second convolutional layer.
        bn1 (nn.BatchNorm2d): Batch normalization layer after the first convolution.
        bn2 (nn.BatchNorm2d): Batch normalization layer after the second convolution.

    Methods:
        forward(input): Performs the forward pass of the residual block.
    """

    def __init__(self, in_channels, out_channels, downsample):
        super().__init__()
        if downsample:
            self.conv1 = nn.Conv2d(
                in_channels, out_channels, kernel_size=3, stride=2, padding=1
            )
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),
                nn.BatchNorm2d(out_channels),
            )
        else:
            self.conv1 = nn.Conv2d(
                in_channels, out_channels, kernel_size=3, stride=1, padding=1
            )
            self.shortcut = nn.Sequential()

        self.conv2 = nn.Conv2d(
            out_channels, out_channels, kernel_size=3, stride=1, padding=1
        )
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.bn2 = nn.BatchNorm2d(out_channels)

    def forward(self, _input):
        """Performs the forward pass of the residual block.

        Args:
            _input (torch.Tensor): Input tensor.

        Returns:
            torch.Tensor: Output tensor after applying the residual block.
        """
        shortcut = self.shortcut(_input)
        _input = nn.Sigmoid()(self.bn1(self.conv1(_input)))
        _input = nn.Sigmoid()(self.bn2(self.conv2(_input)))
        _input = _input + shortcut
        return nn.Sigmoid()(_input)
