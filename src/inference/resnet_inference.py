import os.path

from torch.utils.data import DataLoader

from utils.definitions import TRAINED_DIR, DATA_DIR


class ResNetInference:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        y_pred_test = []
        model = ResNet18(3, 50, Resblock)
        model = model.to(self.device)

        model.load_state_dict(
            torch.load(os.path.join(TRAINED_DIR, "resnet_pretrained.pth"))
        )
        model.eval()
        test_loader = self.load_data()
        with torch.no_grad():
            for data, img_path in test_loader:
                data = data.to(self.device)
                test_output_i = model(data)
                y_pred_test += test_output_i.argmax(dim=1).tolist()
                results_df = pd.DataFrame(
                    {
                        "Image_Path": img_path,
                        "Predicted_Label": y_pred_test,
                    }
                )
                print("WORKING")
                results_df.to_csv(
                    os.path.join(
                        DATA_DIR, os.path.join("test", "preds.csv")
                    ),
                    index=False,
                )

    def load_data(self, batch_size=100):
        eval_transforms = transforms.Compose(
            [transforms.Resize(size=(150, 150)), transforms.ToTensor()]
        )

        test_data = Custom_Dataset(
            os.path.join(DATA_DIR, "test"),
            transform=eval_transforms,
        )
        test_loader = DataLoader(
            dataset=test_data, batch_size=batch_size, shuffle=False
        )
        return test_loader


# File: resnet.py
#
# Author: Thomas Bandy
#
# This file contains the implementation of the ResNet18 model and the Residual Block module in PyTorch.
# The ResNet18 model is a 5-layer variant with 18 convolutional layers.
#
# References:
# - Kaiming He, et al. "Deep Residual Learning for Image Recognition." arXiv:1512.03385
# - https://blog.paperspace.com/writing-resnet-from-scratch-in-pytorch/
# - https://towardsdev.com/implement-resnet-with-pytorch-a9fb40a77448
#
# All docstrings were generated by ChatGPT.
#
# The ResNet18 model is based on the ResNet architecture proposed in the above paper,
# with modifications for the ResNet18 variant.
#
# The Residual Block module is a building block used in the ResNet18 model,
# consisting of convolutional layers, batch normalization, and skip connections.
#
# Date: May 12, 2023

import torch
from torch import nn


class ResNet18(nn.Module):
    """A PyTorch implementation of the ResNet-18 architecture.

    This class implements the ResNet-18 architecture, a widely used deep convolutional neural network architecture
    for image classification tasks. It inherits from the PyTorch nn.Module class.

    Attributes:
        - layer0 (nn.Sequential): The initial layer of the ResNet-18, consisting of a convolution, max pooling, batch
        normalization, and ReLU activation.
        - layer1 (nn.Sequential): The second layer of the ResNet-18, consisting of 2 residual blocks.
        - layer2 (nn.Sequential): The third layer of the ResNet-18, consisting of 2 residual blocks.
        - layer3 (nn.Sequential): The fourth layer of the ResNet-18, consisting of 2 residual blocks.
        - layer4 (nn.Sequential): The fifth layer of the ResNet-18, consisting of 2 residual blocks.
        - gap (torch.nn.AdaptiveAvgPool2d): Global average pooling layer.
        - fc (torch.nn.Linear): Fully connected layer for the network output.
    """

    def __init__(self, in_channels, out_channel, resblock, outputs=6):
        """Constructs all the necessary attributes for the ResNet18 object.

        Args:
            in_channels (int): Number of input channels.

            out_channel (int): Number of output channels for the initial convolutional layer.

            resblock (nn.Module): The type of Residual Block to use. Must be a subclass of nn.Module.

            outputs (int, optional): Number of output units for the last linear layer. Defaults to 1000.
        """

        super().__init__()
        self.layer0 = nn.Sequential(
            nn.Conv2d(in_channels, out_channel, kernel_size=7, stride=2, padding=3),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(out_channel),
            nn.ReLU(),
        )

        self.layer1 = nn.Sequential(
            resblock(out_channel, out_channel, downsample=False),
            resblock(out_channel, out_channel, downsample=False),
        )

        self.layer2 = nn.Sequential(
            resblock(out_channel, (out_channel * 2), downsample=True),
            resblock((out_channel * 2), (out_channel * 2), downsample=False),
        )

        self.layer3 = nn.Sequential(
            resblock((out_channel * 2), (out_channel * 4), downsample=True),
            resblock((out_channel * 4), (out_channel * 4), downsample=False),
        )

        self.layer4 = nn.Sequential(
            resblock((out_channel * 4), (out_channel * 8), downsample=True),
            resblock((out_channel * 8), (out_channel * 8), downsample=False),
        )

        self.gap = torch.nn.AdaptiveAvgPool2d(1)
        self.fc = torch.nn.Linear((out_channel * 8), outputs)

    def forward(self, out):
        """Performs the forward pass of the ResNet18 model.

        Args:
            input (torch.Tensor): Input tensor.

        Returns:
            torch.Tensor: Output tensor after applying the forward pass.
        """
        out = self.layer0(out)
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = self.gap(out)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        return out


class Resblock(nn.Module):
    """A residual block module for a convolutional neural network.

    Args:
        in_channels (int): Number of input channels.
        out_channels (int): Number of output channels.
        downsample (bool): Indicates if the input spatial dimensions need to be downsampled.

    Attributes:
        conv1 (nn.Conv2d): First convolutional layer.
        shortcut (nn.Sequential): Shortcut connection used for downsampling.
        conv2 (nn.Conv2d): Second convolutional layer.
        bn1 (nn.BatchNorm2d): Batch normalization layer after the first convolution.
        bn2 (nn.BatchNorm2d): Batch normalization layer after the second convolution.

    Methods:
        forward(input): Performs the forward pass of the residual block.
    """

    def __init__(self, in_channels, out_channels, downsample):
        super().__init__()
        if downsample:
            self.conv1 = nn.Conv2d(
                in_channels, out_channels, kernel_size=3, stride=2, padding=1
            )
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),
                nn.BatchNorm2d(out_channels),
            )
        else:
            self.conv1 = nn.Conv2d(
                in_channels, out_channels, kernel_size=3, stride=1, padding=1
            )
            self.shortcut = nn.Sequential()

        self.conv2 = nn.Conv2d(
            out_channels, out_channels, kernel_size=3, stride=1, padding=1
        )
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.bn2 = nn.BatchNorm2d(out_channels)

    def forward(self, input):
        """Performs the forward pass of the residual block.

        Args:
            input (torch.Tensor): Input tensor.

        Returns:
            torch.Tensor: Output tensor after applying the residual block.
        """
        shortcut = self.shortcut(input)
        input = nn.ReLU()(self.bn1(self.conv1(input)))
        input = nn.ReLU()(self.bn2(self.conv2(input)))
        input = input + shortcut
        return nn.ReLU()(input)


# File: dataset.py
#
# Author: Thomas Bandy
#
# This file contains the implementation of the Dataset class for loading images and labels from a directory.
#
# All docstrings were generated by ChatGPT.
#
# Date: May 12, 2023

import glob
import os
import torchvision.transforms as transforms

import pandas as pd
from PIL import Image
from torch.utils.data import Dataset


class Custom_Dataset(Dataset):
    """
    Custom dataset class for loading images and labels from a directory.

        Args:
            data_dir (str): Directory path containing the images and labels.
            transform (callable, optional): Optional transform to be applied to the images. Defaults to None.

        Attributes:
            image_paths (list): List of paths to the image files.
            labels (numpy.ndarray): Array of labels corresponding to the images.
            transform (callable): Transform to be applied to the images.
            n (int): Number of samples in the dataset.

        Methods:
            __len__(): Returns the number of samples in the dataset.
            __getitem__(idx): Retrieves the image and its corresponding label at the given index.
    """

    def __init__(self, data_dir, transform=None):
        """
        Initializes the object of the class.

        Args:
            data_dir (str): The directory path containing the image data.
            transform (optional): A transformation to be applied to the images (default: None).

        Attributes:
            image_paths (list): A list of paths to image files.
            labels (ndarray or None): An array of labels corresponding to the images, or None if no labels file found.
            transform: A transformation to be applied to the images.
            n (int): The number of images in the dataset.

        Raises:
            None

        Returns:
            None
        """
        if os.path.exists(os.path.join(data_dir, "buildings")):
            folders = ["buildings", "forest", "glacier", "mountain", "sea", "street"]
            self.image_paths = []
            for folder in folders:
                updated_dir = os.path.join(data_dir + f"\\{folder}")
                self.image_paths += glob.glob(os.path.join(updated_dir, "*.jpg"))
        else:
            self.image_paths = glob.glob(os.path.join(data_dir, "*.jpg"))

        labels_path = os.path.join(data_dir, "values.csv")
        self.labels = (
            pd.read_csv(labels_path, header=None).to_numpy()[:, 1][1:].astype(int)
            if os.path.isfile(labels_path)
            else None
        )
        self.image_paths.sort()
        self.transform = transform
        self.n = len(self.image_paths)

    def __len__(self):
        """Returns the number of samples in the dataset.

        Returns:
            int: Number of samples in the dataset.
        """
        return self.n

    def __getitem__(self, idx):
        """Retrieves the image and its corresponding label at the given index.

        Args:
            idx (int): Index of the sample to retrieve.

        Returns:
            tuple: Tuple containing the transformed image and its label.
        """
        img_path = self.image_paths[idx]
        transform = transforms.Compose(
            [
                transforms.Resize((150, 150)),
                transforms.ToTensor(),
            ]
        )
        img = Image.open(img_path)
        img_transformed = transform(img)  # Modify to suit resnet and alexnet
        if self.labels is None:
            if img_path.split("\\")[-2] == "buildings":
                label = 0
            elif img_path.split("\\")[-2] == "forest":
                label = 1
            elif img_path.split("\\")[-2] == "glacier":
                label = 2
            elif img_path.split("\\")[-2] == "mountain":
                label = 3
            elif img_path.split("\\")[-2] == "sea":
                label = 4
            elif img_path.split("\\")[-2] == "street":
                label = 5
            else:
                return img_transformed, img_path.split("\\")[-1]
        else:
            label = self.labels[idx]
        return img_transformed, label, img_path.split("\\")[-1]


if __name__ == "__main__":
    Inference()
